{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T14:12:49.939518Z",
     "start_time": "2025-05-08T14:12:49.935487Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import h5py, os\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from Bio import SeqIO\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score"
   ],
   "id": "65b80f22c6be92cd",
   "outputs": [],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T14:12:50.531457Z",
     "start_time": "2025-05-08T14:12:50.527615Z"
    }
   },
   "cell_type": "code",
   "source": "from training.naive_bayes.naive_bayes import tokenize_genes_substring",
   "id": "b613637eeb624906",
   "outputs": [],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T14:13:57.852358Z",
     "start_time": "2025-05-08T14:12:51.103973Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenized_sequences_test = tokenize_genes_substring(\"../../paperData/pM10Kb_1KTest/human_promoter_sequences_test.fasta\", 3500, 13501)\n",
    "tokenized_sequences_val = tokenize_genes_substring(\"../../paperData/pM10Kb_1KTest/human_promoter_sequences_valid.fasta\", 3500, 13501)\n",
    "tokenized_sequences_training = tokenize_genes_substring(\"../../paperData/pM10Kb_1KTest/human_promoter_sequences_train.fasta\", 3500, 13501)\n",
    "tokenized_sequences = np.concatenate((tokenized_sequences_test, tokenized_sequences_val, tokenized_sequences_training), axis=None)\n",
    "print(len(tokenized_sequences))"
   ],
   "id": "4ab1052a46369478",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenize_genes_substring CALLED\n",
      "tokenize_genes_substring CALLED\n",
      "tokenize_genes_substring CALLED\n",
      "18377\n"
     ]
    }
   ],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T14:15:44.688368Z",
     "start_time": "2025-05-08T14:14:02.278581Z"
    }
   },
   "cell_type": "code",
   "source": [
    "datadir = \"..\\\\..\\\\paperData\\\\pM10Kb_1KTest\"\n",
    "\n",
    "# Get truth data\n",
    "testfile = h5py.File(os.path.join(datadir, 'test.h5'), 'r')\n",
    "valfile = h5py.File(os.path.join(datadir, 'valid.h5'), 'r')\n",
    "trainfile = h5py.File(os.path.join(datadir, 'train.h5'), 'r')\n",
    "y = np.concatenate((testfile['detectionFlagInt'][:], valfile['detectionFlagInt'][:], trainfile['detectionFlagInt'][:]), axis=None)\n",
    "print(\"y.shape: \", y.shape)\n",
    "\n",
    "# exclude genes if expression is unknown i.e., 2\n",
    "excluded_indices = [i for i in range(len(y)) if y[i] == 2]\n",
    "y = [label for (idx, label) in enumerate(y) if idx not in excluded_indices]\n",
    "tokenized_sequences = [seq for (idx, seq) in enumerate(tokenized_sequences) if idx not in excluded_indices]\n",
    "\n",
    "# Use CountVectorizer to count k-mers\n",
    "vectorizer = CountVectorizer()\n",
    "#vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(tokenized_sequences)\n",
    "\n",
    "# You now have a sparse matrix of k-mer counts\n",
    "print(\"X.shape\", X.shape)  # (num_sequences, num_unique_kmers)print(\"y.shape\", y.shape)\n",
    "print(\"len(y)\", len(y))\n",
    "\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05, random_state=0)"
   ],
   "id": "2b867cd5e87781d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y.shape:  (18377,)\n",
      "X.shape (18344, 4150)\n",
      "len(y) 18344\n"
     ]
    }
   ],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T14:15:46.168586Z",
     "start_time": "2025-05-08T14:15:45.982381Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from scipy.sparse import vstack\n",
    "absent_idx = [idx for (idx, label) in enumerate(y_train) if label == 0]\n",
    "present_idx = [idx for (idx, label) in enumerate(y_train) if label == 1][:len(absent_idx)]\n",
    "absent_X = X_train[absent_idx]\n",
    "present_X = X_train[present_idx]\n",
    "absent_y = [l for l in y_train if l == 0]\n",
    "present_y = [l for l in y_train if l == 1][:len(absent_y)]\n",
    "X_train_filter = vstack([absent_X, present_X])\n",
    "y_train_filter = np.concatenate((absent_y, present_y), axis=None)\n",
    "\n",
    "test_number_of_present = len([label for label in y_test if label == 1])\n",
    "test_number_of_absent = len([label for label in y_test if label == 0])\n",
    "print(\"Number of test genes:\", len(y_test))\n",
    "print(\"y stats: Number of present:\", test_number_of_present,\" and number of absent:\", test_number_of_absent)\n",
    "print(\"Percentage of present:\", test_number_of_present / len(y_test) * 100)\n",
    "\n",
    "train_number_of_present = len([label for label in y_train_filter if label == 1])\n",
    "train_number_of_absent = len([label for label in y_train_filter if label == 0])\n",
    "print(\"Number of train genes:\", len(y_train_filter))\n",
    "print(\"y stats: Number of present:\", train_number_of_present,\" and number of absent:\", train_number_of_absent)"
   ],
   "id": "574f8490f2a07ecb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test genes: 918\n",
      "y stats: Number of present: 769  and number of absent: 149\n",
      "Percentage of present: 83.76906318082789\n",
      "Number of train genes: 4918\n",
      "y stats: Number of present: 2459  and number of absent: 2459\n"
     ]
    }
   ],
   "execution_count": 61
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T14:15:47.599341Z",
     "start_time": "2025-05-08T14:15:47.489060Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Fit Naive Bayes\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train_filter, y_train_filter)\n",
    "\n",
    "# Predict and evaluate\n",
    "test_pred = model.predict(X_test)\n",
    "print(\"FOR CountVectorizer\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, test_pred))\n",
    "print(\"Precision:\", precision_score(y_test, test_pred))\n",
    "print(\"Recall:\", recall_score(y_test, test_pred))\n",
    "print(\"F1-score:\", f1_score(y_test, test_pred))\n",
    "tf = sum([1 for idx, label in enumerate(test_pred) if test_pred[idx] == y_test[idx] and y_test[idx] == 1])\n",
    "tn = sum([1 for idx, label in enumerate(test_pred) if test_pred[idx] == y_test[idx] and y_test[idx] == 0])\n",
    "fp = sum([1 for idx, label in enumerate(test_pred) if test_pred[idx] != y_test[idx] and y_test[idx] == 0])\n",
    "fn = sum([1 for idx, label in enumerate(test_pred) if test_pred[idx] != y_test[idx] and y_test[idx] == 1])\n",
    "print(\"Number of true positives:\", tf)\n",
    "print(\"Number of true negatives:\", tn)\n",
    "print(\"Number of false positives:\", fp)\n",
    "print(\"Number of false negatives:\", fn)\n",
    "print(\"Negative precision (Out of all the negative predictions we made, how many were actually negative?):\", tn/(tn+fn))\n",
    "print(\"Negative recall (Out of all the sequences that should be predicted as unexpressed, how many did we correctly predict as unexpressed?):\", tn/(tn+fp))"
   ],
   "id": "a2e0e056f298ccde",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOR CountVectorizer\n",
      "Accuracy: 0.659041394335512\n",
      "Precision: 0.9206642066420664\n",
      "Recall: 0.6488946684005201\n",
      "F1-score: 0.7612509534706331\n",
      "Number of true positives: 499\n",
      "Number of true negatives: 106\n",
      "Number of false positives: 43\n",
      "Number of false negatives: 270\n",
      "Negative precision (Out of all the negative predictions we made, how many were actually negative?): 0.28191489361702127\n",
      "Negative recall (Out of all the sequences that should be predicted as unexpressed, how many did we correctly predict as unexpressed?): 0.7114093959731543\n"
     ]
    }
   ],
   "execution_count": 62
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T14:17:23.041188Z",
     "start_time": "2025-05-08T14:15:48.893201Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# REPEATED FOR TFIDF\n",
    "# Use CountVectorizer to count k-mers\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(tokenized_sequences)\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05, random_state=0)\n",
    "\n",
    "absent_idx = [idx for (idx, label) in enumerate(y_train) if label == 0]\n",
    "present_idx = [idx for (idx, label) in enumerate(y_train) if label == 1][:len(absent_idx)]\n",
    "absent_X = X_train[absent_idx]\n",
    "present_X = X_train[present_idx]\n",
    "absent_y = [l for l in y_train if l == 0]\n",
    "present_y = [l for l in y_train if l == 1][:len(absent_y)]\n",
    "X_train_filter = vstack([absent_X, present_X])\n",
    "y_train_filter = np.concatenate((absent_y, present_y), axis=None)\n",
    "\n",
    "test_number_of_present = len([label for label in y_test if label == 1])\n",
    "test_number_of_absent = len([label for label in y_test if label == 0])\n",
    "print(\"Number of test genes:\", len(y_test))\n",
    "print(\"y stats: Number of present:\", test_number_of_present,\" and number of absent:\", test_number_of_absent)\n",
    "print(\"Percentage of present:\", test_number_of_present / len(y_test) * 100)\n",
    "\n",
    "train_number_of_present = len([label for label in y_train_filter if label == 1])\n",
    "train_number_of_absent = len([label for label in y_train_filter if label == 0])\n",
    "print(\"Number of train genes:\", len(y_train_filter))\n",
    "print(\"y stats: Number of present:\", train_number_of_present,\" and number of absent:\", train_number_of_absent)"
   ],
   "id": "361d945f7828cdab",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test genes: 918\n",
      "y stats: Number of present: 769  and number of absent: 149\n",
      "Percentage of present: 83.76906318082789\n",
      "Number of train genes: 4918\n",
      "y stats: Number of present: 2459  and number of absent: 2459\n"
     ]
    }
   ],
   "execution_count": 63
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T14:17:24.558303Z",
     "start_time": "2025-05-08T14:17:24.446184Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Fit Naive Bayes\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train_filter, y_train_filter)\n",
    "\n",
    "# Predict and evaluate\n",
    "test_pred = model.predict(X_test)\n",
    "print(\"FOR TfidfVectorizer\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, test_pred))\n",
    "print(\"Precision:\", precision_score(y_test, test_pred))\n",
    "print(\"Recall:\", recall_score(y_test, test_pred))\n",
    "print(\"F1-score:\", f1_score(y_test, test_pred))\n",
    "tf = sum([1 for idx, label in enumerate(test_pred) if test_pred[idx] == y_test[idx] and y_test[idx] == 1])\n",
    "tn = sum([1 for idx, label in enumerate(test_pred) if test_pred[idx] == y_test[idx] and y_test[idx] == 0])\n",
    "fp = sum([1 for idx, label in enumerate(test_pred) if test_pred[idx] != y_test[idx] and y_test[idx] == 0])\n",
    "fn = sum([1 for idx, label in enumerate(test_pred) if test_pred[idx] != y_test[idx] and y_test[idx] == 1])\n",
    "print(\"Number of true positives:\", tf)\n",
    "print(\"Number of true negatives:\", tn)\n",
    "print(\"Number of false positives:\", fp)\n",
    "print(\"Number of false negatives:\", fn)\n",
    "print(\"Negative precision (Out of all the negative predictions we made, how many were actually negative?):\", tn/(tn+fn))\n",
    "print(\"Negative recall (Out of all the sequences that should be predicted as unexpressed, how many did we correctly predict as unexpressed?):\", tn/(tn+fp))"
   ],
   "id": "25bc7853b0f15fc0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOR TfidfVectorizer\n",
      "Accuracy: 0.6612200435729847\n",
      "Precision: 0.922509225092251\n",
      "Recall: 0.6501950585175552\n",
      "F1-score: 0.7627765064836003\n",
      "Number of true positives: 500\n",
      "Number of true negatives: 107\n",
      "Number of false positives: 42\n",
      "Number of false negatives: 269\n",
      "Negative precision (Out of all the negative predictions we made, how many were actually negative?): 0.2845744680851064\n",
      "Negative recall (Out of all the sequences that should be predicted as unexpressed, how many did we correctly predict as unexpressed?): 0.7181208053691275\n"
     ]
    }
   ],
   "execution_count": 64
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
